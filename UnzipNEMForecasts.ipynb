{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGf9O1L9JIlqOobhVzFIiC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/redaxe101/MastersThesisNotebook/blob/main/UnzipNEMForecasts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## National Electricity Market Pre-processing\n",
        "\n",
        "Pre-processes NEM zip files to extract relevant features.\n",
        "\n",
        "Data downloaded from https://visualisations.aemo.com.au/aemo/nemweb/index.html#mms-data-model"
      ],
      "metadata": {
        "id": "uyMQdHucuvRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os, zipfile, csv\n",
        "from collections import defaultdict\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Setup paths\n",
        "drive_root = \"/content/drive/MyDrive\"\n",
        "source_dir = os.path.join(drive_root, \"NEM\")\n",
        "output_dir = os.path.join(source_dir, \"older_pre_dispatch/output\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Log file to track processed zips\n",
        "log_path = os.path.join(output_dir, \"processed_zips.log\")\n",
        "processed_zips = set()\n",
        "if os.path.exists(log_path):\n",
        "    with open(log_path, \"r\") as log_file:\n",
        "        processed_zips = set(line.strip() for line in log_file)\n",
        "\n",
        "# Track headers\n",
        "region_headers = []\n",
        "price_headers = []\n",
        "got_headers = False\n",
        "got_price_headers = False\n",
        "\n",
        "# Loop through all zip files sorted\n",
        "zip_files = sorted(f for f in os.listdir(source_dir) if f.lower().endswith(\".zip\"))\n",
        "\n",
        "for filename in zip_files:\n",
        "    if filename in processed_zips:\n",
        "        continue\n",
        "\n",
        "    zip_path = os.path.join(source_dir, filename)\n",
        "    print(f\"üì¶ Processing: {filename}\")\n",
        "\n",
        "    run_datetime_map = {}\n",
        "    rrp_map = {}\n",
        "    region_data = defaultdict(list)\n",
        "    rrp_data = defaultdict(list)\n",
        "\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as outer:\n",
        "            for nested_name in outer.namelist():\n",
        "                if not nested_name.lower().endswith(\".zip\"):\n",
        "                    continue\n",
        "\n",
        "                with outer.open(nested_name) as nested_zip_file:\n",
        "                    try:\n",
        "                        with zipfile.ZipFile(nested_zip_file) as nested:\n",
        "                            for csv_name in nested.namelist():\n",
        "                                if not csv_name.lower().endswith(\".csv\"):\n",
        "                                    continue\n",
        "\n",
        "                                print(f\"   ‚Üí Reading CSV: {csv_name}\")\n",
        "                                with nested.open(csv_name) as file:\n",
        "                                    decoded = (line.decode(\"utf-8\") for line in file)\n",
        "                                    reader = csv.reader(decoded)\n",
        "\n",
        "                                    for row in reader:\n",
        "                                        if not row:\n",
        "                                            continue\n",
        "\n",
        "                                        if row[0] == \"I\" and row[2] == \"REGION_SOLUTION\" and not got_headers:\n",
        "                                            region_headers = [\"RUN_DATETIME\"] + row\n",
        "                                            got_headers = True\n",
        "                                            continue\n",
        "\n",
        "                                        if row[0] == \"I\" and row[2] == \"REGION_PRICES\" and not got_price_headers:\n",
        "                                            price_headers = [\"RUN_DATETIME\"] + row\n",
        "                                            got_price_headers = True\n",
        "                                            continue\n",
        "\n",
        "                                        if row[0].startswith(\"C\") or row[0].startswith(\"I\"):\n",
        "                                            continue\n",
        "\n",
        "                                        if row[1] != \"PREDISPATCH\":\n",
        "                                            continue\n",
        "\n",
        "                                        record_type = row[2]\n",
        "\n",
        "                                        if record_type == \"CASE_SOLUTION\":\n",
        "                                            try:\n",
        "                                                seqno = row[4]\n",
        "                                                run_dt = row[-2]\n",
        "                                                run_datetime_map[seqno] = run_dt\n",
        "                                            except IndexError:\n",
        "                                                continue\n",
        "\n",
        "                                        elif record_type == \"REGION_SOLUTION\":\n",
        "                                            try:\n",
        "                                                seqno = row[4]\n",
        "                                                region = row[6]\n",
        "                                                run_dt = run_datetime_map.get(seqno, \"UNKNOWN\")\n",
        "                                                if run_dt > \"2024-06-01\":\n",
        "                                                  region_data[region].append([run_dt] + row)\n",
        "                                            except IndexError:\n",
        "                                                continue\n",
        "\n",
        "                                        elif record_type == \"REGION_PRICES\":\n",
        "                                            try:\n",
        "                                                seqno = row[4]\n",
        "                                                region = row[6]\n",
        "                                                run_dt = run_datetime_map.get(seqno, \"UNKNOWN\")\n",
        "                                                if run_dt > \"2024-06-01\":\n",
        "                                                  rrp_data[region].append([run_dt] + row)\n",
        "                                            except IndexError:\n",
        "                                                continue\n",
        "\n",
        "                    except zipfile.BadZipFile:\n",
        "                        print(f\"‚ö†Ô∏è Could not open nested ZIP: {nested_name}\")\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"‚ö†Ô∏è Could not open main ZIP: {filename}\")\n",
        "        continue\n",
        "\n",
        "    # Save per region\n",
        "    for region, records in region_data.items():\n",
        "        print(f\"   ‚Üí Writing {len(records)} rows for {region}\")\n",
        "        out_path = os.path.join(output_dir, f\"{region}_pre_dispatch.csv\")\n",
        "        write_header = not os.path.exists(out_path)\n",
        "\n",
        "        with open(out_path, \"a\", newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            if write_header:\n",
        "                writer.writerow(region_headers)\n",
        "            writer.writerows(records)\n",
        "\n",
        "    # Save prices per region\n",
        "    for region, records in rrp_data.items():\n",
        "        print(f\"   ‚Üí Writing {len(records)} pricing rows for {region}\")\n",
        "        out_path = os.path.join(output_dir, f\"{region}_prices.csv\")\n",
        "        write_header = not os.path.exists(out_path)\n",
        "\n",
        "        with open(out_path, \"a\", newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            if write_header:\n",
        "                writer.writerow(price_headers)\n",
        "            writer.writerows(records)\n",
        "\n",
        "    # Log the processed zip\n",
        "    with open(log_path, \"a\") as log_file:\n",
        "        log_file.write(filename + \"\\n\")\n",
        "\n",
        "print(\"‚úÖ All ZIPs processed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4Ifd5_Di1Sw",
        "outputId": "3f4170bc-4a52-4e2d-8751-7ce93c9d170a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ All ZIPs processed.\n"
          ]
        }
      ]
    }
  ]
}